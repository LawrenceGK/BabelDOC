"""
ä»»åŠ¡ç®¡ç†ç³»ç»Ÿ
ç®¡ç†ç¿»è¯‘ä»»åŠ¡çš„ç”Ÿå‘½å‘¨æœŸï¼ŒåŒ…æ‹¬åˆ›å»ºã€æ‰§è¡Œã€ç›‘æ§å’Œç»“æœç®¡ç†
"""
import asyncio
import logging
import threading
import traceback
import uuid
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Callable, Any
import json
import tempfile

from babeldoc.api.models import TaskStatus, TaskInfo, TranslationRequest, OutputFileInfo
from babeldoc.api.cache import get_cache, FileCache
from babeldoc.format.pdf.translation_config import TranslationConfig, WatermarkOutputMode
from babeldoc.translator.translator import OpenAITranslator, set_translate_rate_limiter
from babeldoc.glossary import Glossary

logger = logging.getLogger(__name__)


class TaskProgressCallback:
    """ä»»åŠ¡è¿›åº¦å›è°ƒ"""
    
    def __init__(self, task_id: str, task_manager: 'TaskManager'):
        self.task_id = task_id
        self.task_manager = task_manager
        self.last_progress = 0.0
        self.last_message = ""

    def __call__(self, progress: float, message: str = "", stage: str = ""):
        """æ›´æ–°ä»»åŠ¡è¿›åº¦"""
        try:
            self.last_progress = progress
            self.last_message = message
            
            self.task_manager.update_task_progress(
                self.task_id, 
                progress, 
                message, 
                stage
            )
        except Exception as e:
            logger.error(f"æ›´æ–°ä»»åŠ¡è¿›åº¦å¤±è´¥ {self.task_id}: {e}")


class TaskManager:
    """ä»»åŠ¡ç®¡ç†å™¨ - ä½¿ç”¨ CLI ç›¸åŒçš„å¹¶è¡Œå¤„ç†ä¼˜åŒ–"""
    
    def __init__(self, max_concurrent_tasks: int = 3):
        self.max_concurrent_tasks = max_concurrent_tasks
        self.tasks: Dict[str, TaskInfo] = {}
        self.task_locks: Dict[str, threading.RLock] = {}
        self.progress_callbacks: Dict[str, List[Callable]] = {}
        
        # ğŸš€ ä¼˜åŒ–ï¼šä½¿ç”¨ä¼˜å…ˆçº§çº¿ç¨‹æ± æ‰§è¡Œå™¨ï¼Œä¸CLIä¿æŒä¸€è‡´
        from babeldoc.utils.priority_thread_pool_executor import PriorityThreadPoolExecutor
        self.processing_tasks = set()
        self.translation_executor = PriorityThreadPoolExecutor(
            max_workers=max_concurrent_tasks * 2,  # å…è®¸æ›´å¤šå¹¶è¡Œåº¦
            thread_name_prefix="BabelDoc-Translation"
        )
        
        # ç¼“å­˜ç®¡ç†
        self.file_cache: FileCache = get_cache('uploaded_files', max_age_days=7)
        self.result_cache: FileCache = get_cache('translation_results', max_age_days=30)
        
        # ä»»åŠ¡æŒä¹…åŒ–
        self.task_data_file = Path(tempfile.gettempdir()) / "babeldoc_tasks.json"
        
        # ä»»åŠ¡ç»“æœç›®å½•
        self.results_base_dir = Path(tempfile.gettempdir()) / "babeldoc_results"
        self.results_base_dir.mkdir(parents=True, exist_ok=True)
        
        # é”
        self._lock = threading.RLock()
        
        # åŠ è½½å·²æœ‰ä»»åŠ¡
        self._load_tasks()
        
        # å¯åŠ¨æ¸…ç†çº¿ç¨‹
        self._start_cleanup_thread()
        
        logger.info(f"ä»»åŠ¡ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œæœ€å¤§å¹¶å‘ä»»åŠ¡æ•°: {max_concurrent_tasks}")

    def __del__(self):
        """æ¸…ç†èµ„æº"""
        try:
            if hasattr(self, 'translation_executor'):
                self.translation_executor.shutdown(wait=True)
        except Exception as e:
            logger.error(f"æ¸…ç†ä»»åŠ¡ç®¡ç†å™¨èµ„æºå¤±è´¥: {e}")

    def _load_tasks(self):
        """åŠ è½½æŒä¹…åŒ–çš„ä»»åŠ¡æ•°æ®"""
        try:
            if self.task_data_file.exists():
                with open(self.task_data_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for task_data in data.get('tasks', []):
                        try:
                            # æ•°æ®è¿ç§»ï¼šå¤„ç†è€æ ¼å¼çš„ output_files
                            if 'output_files' in task_data and isinstance(task_data['output_files'], list):
                                # æ£€æŸ¥æ˜¯å¦æ˜¯è€æ ¼å¼ï¼ˆå­—ç¬¦ä¸²åˆ—è¡¨ï¼‰
                                if task_data['output_files'] and isinstance(task_data['output_files'][0], str):
                                    # è½¬æ¢ä¸ºæ–°æ ¼å¼
                                    old_output_files = task_data['output_files']
                                    task_data['output_file_paths'] = old_output_files.copy()  # å‘åå…¼å®¹
                                    task_data['output_files'] = []
                                    
                                    # å°è¯•ä»æ–‡ä»¶è·¯å¾„æ¨æ–­ç»“æ„åŒ–ä¿¡æ¯
                                    for file_path in old_output_files:
                                        try:
                                            if Path(file_path).exists():
                                                file_info = OutputFileInfo.from_file_path(file_path)
                                                task_data['output_files'].append(file_info.model_dump())
                                        except Exception as e:
                                            logger.warning(f"è¿ç§»è¾“å‡ºæ–‡ä»¶æ•°æ®å¤±è´¥ {file_path}: {e}")
                            
                            # ç¡®ä¿å‘åå…¼å®¹å­—æ®µå­˜åœ¨
                            if 'output_file_paths' not in task_data:
                                task_data['output_file_paths'] = []
                            
                            # å°†å­—å…¸è½¬æ¢ä¸º TaskInfo å¯¹è±¡
                            task_info = TaskInfo(**task_data)
                            
                            # é‡ç½®å¤„ç†ä¸­çš„ä»»åŠ¡çŠ¶æ€
                            if task_info.status == TaskStatus.PROCESSING:
                                task_info.status = TaskStatus.FAILED
                                task_info.error_message = "æœåŠ¡é‡å¯ï¼Œä»»åŠ¡ä¸­æ–­"
                                task_info.updated_at = datetime.now()
                            
                            self.tasks[task_info.task_id] = task_info
                            self.task_locks[task_info.task_id] = threading.RLock()
                            
                        except Exception as e:
                            logger.error(f"åŠ è½½ä»»åŠ¡æ•°æ®å¤±è´¥: {e}")
                            
                logger.info(f"åŠ è½½äº† {len(self.tasks)} ä¸ªå†å²ä»»åŠ¡")
        except Exception as e:
            logger.error(f"åŠ è½½ä»»åŠ¡æŒä¹…åŒ–æ•°æ®å¤±è´¥: {e}")

    def _save_tasks(self):
        """ä¿å­˜ä»»åŠ¡æ•°æ®åˆ°æ–‡ä»¶"""
        try:
            # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
            serializable_tasks = []
            for task in self.tasks.values():
                task_dict = task.model_dump()
                # è½¬æ¢ datetime å¯¹è±¡
                for key in ['created_at', 'updated_at']:
                    if key in task_dict and isinstance(task_dict[key], datetime):
                        task_dict[key] = task_dict[key].isoformat()
                serializable_tasks.append(task_dict)
            
            data = {
                'tasks': serializable_tasks,
                'saved_at': datetime.now().isoformat()
            }
            
            with open(self.task_data_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            logger.error(f"ä¿å­˜ä»»åŠ¡æ•°æ®å¤±è´¥: {e}")

    def _start_cleanup_thread(self):
        """å¯åŠ¨ä»»åŠ¡æ¸…ç†çº¿ç¨‹"""
        def cleanup_worker():
            while True:
                try:
                    self._cleanup_old_tasks()
                    threading.Event().wait(3600)  # æ¯å°æ—¶æ¸…ç†ä¸€æ¬¡
                except Exception as e:
                    logger.error(f"ä»»åŠ¡æ¸…ç†çº¿ç¨‹å‡ºé”™: {e}")
                    threading.Event().wait(300)  # å‡ºé”™æ—¶5åˆ†é’Ÿåé‡è¯•
        
        cleanup_thread = threading.Thread(target=cleanup_worker, daemon=True)
        cleanup_thread.start()
        logger.info("å¯åŠ¨ä»»åŠ¡æ¸…ç†çº¿ç¨‹")

    def _cleanup_old_tasks(self):
        """æ¸…ç†è¿‡æœŸä»»åŠ¡å’Œç»“æœæ–‡ä»¶"""
        with self._lock:
            current_time = datetime.now()
            cutoff_time = current_time - timedelta(days=7)  # ä¿ç•™7å¤©çš„ä»»åŠ¡è®°å½•
            
            to_remove = []
            for task_id, task in self.tasks.items():
                if task.updated_at < cutoff_time and task.status in [
                    TaskStatus.COMPLETED, TaskStatus.FAILED, TaskStatus.CANCELLED
                ]:
                    to_remove.append(task_id)
            
            for task_id in to_remove:
                # æ¸…ç†ç»“æœæ–‡ä»¶
                try:
                    result_dir = self.results_base_dir / task_id
                    if result_dir.exists():
                        import shutil
                        shutil.rmtree(result_dir, ignore_errors=True)
                        logger.info(f"æ¸…ç†ä»»åŠ¡ {task_id} çš„ç»“æœæ–‡ä»¶ç›®å½•: {result_dir}")
                except Exception as e:
                    logger.warning(f"æ¸…ç†ä»»åŠ¡ {task_id} ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
                
                # æ¸…ç†ä»»åŠ¡è®°å½•
                del self.tasks[task_id]
                if task_id in self.task_locks:
                    del self.task_locks[task_id]
                if task_id in self.progress_callbacks:
                    del self.progress_callbacks[task_id]
            
            if to_remove:
                logger.info(f"æ¸…ç†äº† {len(to_remove)} ä¸ªè¿‡æœŸä»»åŠ¡")
                self._save_tasks()

    def create_task(
        self, 
        request: TranslationRequest, 
        input_file_path: Path,
        input_filename: str
    ) -> str:
        """åˆ›å»ºæ–°ä»»åŠ¡"""
        task_id = str(uuid.uuid4())
        
        with self._lock:
            # åˆ›å»ºä»»åŠ¡ä¿¡æ¯
            task_info = TaskInfo(
                task_id=task_id,
                status=TaskStatus.PENDING,
                progress=0.0,
                message="ä»»åŠ¡å·²åˆ›å»ºï¼Œç­‰å¾…å¤„ç†",
                created_at=datetime.now(),
                updated_at=datetime.now(),
                input_filename=input_filename,
                input_file_size=input_file_path.stat().st_size,
                lang_in=request.lang_in,
                lang_out=request.lang_out,
                pages=request.pages,
                output_files=[]
            )
            
            self.tasks[task_id] = task_info
            self.task_locks[task_id] = threading.RLock()
            self.progress_callbacks[task_id] = []
            
            # ä¿å­˜ä»»åŠ¡æ•°æ®
            self._save_tasks()
            
            logger.info(f"åˆ›å»ºç¿»è¯‘ä»»åŠ¡: {task_id}")
            return task_id

    def get_task(self, task_id: str) -> Optional[TaskInfo]:
        """è·å–ä»»åŠ¡ä¿¡æ¯"""
        return self.tasks.get(task_id)

    def list_tasks(self, page: int = 1, page_size: int = 20) -> tuple[List[TaskInfo], int]:
        """åˆ—å‡ºä»»åŠ¡"""
        with self._lock:
            # æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åˆ—
            sorted_tasks = sorted(
                self.tasks.values(), 
                key=lambda x: x.created_at, 
                reverse=True
            )
            
            total = len(sorted_tasks)
            start_idx = (page - 1) * page_size
            end_idx = start_idx + page_size
            
            page_tasks = sorted_tasks[start_idx:end_idx]
            return page_tasks, total

    def update_task_progress(
        self, 
        task_id: str, 
        progress: float, 
        message: str = "",
        stage: str = ""
    ):
        """æ›´æ–°ä»»åŠ¡è¿›åº¦"""
        if task_id not in self.tasks:
            return
        
        with self.task_locks.get(task_id, threading.RLock()):
            task = self.tasks[task_id]
            task.progress = max(0, min(100, progress))
            if message:
                task.message = message
            task.updated_at = datetime.now()
            
            # é€šçŸ¥è¿›åº¦å›è°ƒ
            for callback in self.progress_callbacks.get(task_id, []):
                try:
                    callback(progress, message, stage)
                except Exception as e:
                    logger.error(f"è¿›åº¦å›è°ƒå¤±è´¥: {e}")
            
            # ä¿å­˜ä»»åŠ¡æ•°æ®
            self._save_tasks()

    def update_task_status(
        self, 
        task_id: str, 
        status: TaskStatus, 
        message: str = "",
        error_message: Optional[str] = None,
        error_traceback: Optional[str] = None
    ):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        if task_id not in self.tasks:
            return
        
        with self.task_locks.get(task_id, threading.RLock()):
            task = self.tasks[task_id]
            task.status = status
            if message:
                task.message = message
            if error_message:
                task.error_message = error_message
            if error_traceback:
                task.error_traceback = error_traceback
            task.updated_at = datetime.now()
            
            if status in [TaskStatus.COMPLETED, TaskStatus.FAILED, TaskStatus.CANCELLED]:
                self.processing_tasks.discard(task_id)
            
            # ä¿å­˜ä»»åŠ¡æ•°æ®
            self._save_tasks()

    def add_output_file(self, task_id: str, file_path: str):
        """æ·»åŠ è¾“å‡ºæ–‡ä»¶"""
        if task_id not in self.tasks:
            return
        
        with self.task_locks.get(task_id, threading.RLock()):
            task = self.tasks[task_id]
            
            # åˆ›å»ºç»“æ„åŒ–æ–‡ä»¶ä¿¡æ¯
            try:
                file_info = OutputFileInfo.from_file_path(file_path)
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒæ–‡ä»¶
                if not any(existing.file_path == file_path for existing in task.output_files):
                    task.output_files.append(file_info)
                    
                    # å‘åå…¼å®¹ï¼šåŒæ—¶æ›´æ–°å­—ç¬¦ä¸²åˆ—è¡¨
                    if file_path not in task.output_file_paths:
                        task.output_file_paths.append(file_path)
                    
                    logger.info(f"æ·»åŠ è¾“å‡ºæ–‡ä»¶: {file_path}, ç±»å‹: {file_info.file_type.value}")
                
            except Exception as e:
                logger.error(f"æ·»åŠ è¾“å‡ºæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                # å…œåº•ï¼šè‡³å°‘ä¿è¯å­—ç¬¦ä¸²åˆ—è¡¨ä¸­æœ‰è®°å½•
                if file_path not in task.output_file_paths:
                    task.output_file_paths.append(file_path)
            
            task.updated_at = datetime.now()
            
            # ä¿å­˜ä»»åŠ¡æ•°æ®
            self._save_tasks()

    def register_progress_callback(self, task_id: str, callback: Callable):
        """æ³¨å†Œè¿›åº¦å›è°ƒ"""
        if task_id not in self.progress_callbacks:
            self.progress_callbacks[task_id] = []
        self.progress_callbacks[task_id].append(callback)

    def can_start_task(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥å¯åŠ¨æ–°ä»»åŠ¡"""
        return len(self.processing_tasks) < self.max_concurrent_tasks

    async def execute_task(self, task_id: str, request: TranslationRequest, input_file_path: Path):
        """æ‰§è¡Œç¿»è¯‘ä»»åŠ¡ - ä¼˜åŒ–ç‰ˆï¼Œä½¿ç”¨ä¼˜å…ˆçº§è°ƒåº¦"""
        if not self.can_start_task():
            logger.warning(f"è¾¾åˆ°æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°é™åˆ¶ï¼Œä»»åŠ¡ {task_id} éœ€è¦ç­‰å¾…")
            # TODO: å¯ä»¥å®ç°é˜Ÿåˆ—æœºåˆ¶
            return
        
        self.processing_tasks.add(task_id)
        self.update_task_status(task_id, TaskStatus.PROCESSING, "å¼€å§‹å¤„ç†ç¿»è¯‘ä»»åŠ¡")
        
        # è®¡ç®—ä»»åŠ¡ä¼˜å…ˆçº§ï¼ˆåŸºäºæ–‡ä»¶å¤§å°å’ŒQPSè®¾ç½®ï¼‰
        file_size = input_file_path.stat().st_size
        priority = max(1000000 - file_size // 1024, 1)  # è¶Šå°æ–‡ä»¶ä¼˜å…ˆçº§è¶Šé«˜
        
        try:
            # ğŸš€ å…³é”®ä¼˜åŒ–ï¼šä½¿ç”¨ä¼˜å…ˆçº§çº¿ç¨‹æ± æ‰§è¡Œç¿»è¯‘ä»»åŠ¡
            future = self.translation_executor.submit(
                self._execute_task_sync,
                task_id, request, input_file_path,
                priority=priority
            )
            
            # ç­‰å¾…ä»»åŠ¡å®Œæˆ
            await asyncio.get_event_loop().run_in_executor(None, future.result)
            
            logger.info(f"ä»»åŠ¡ {task_id} æ‰§è¡ŒæˆåŠŸ")
            
        except Exception as e:
            error_msg = f"ç¿»è¯‘ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}"
            error_traceback = traceback.format_exc()
            
            self.update_task_status(
                task_id, 
                TaskStatus.FAILED, 
                error_msg,
                error_msg,
                error_traceback
            )
            
            logger.error(f"ä»»åŠ¡ {task_id} æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            
        finally:
            self.processing_tasks.discard(task_id)

    def _execute_task_sync(self, task_id: str, request: TranslationRequest, input_file_path: Path):
        """åŒæ­¥æ‰§è¡Œç¿»è¯‘ä»»åŠ¡ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­è°ƒç”¨ï¼‰- ä¼˜åŒ–ç‰ˆæœ¬ï¼Œæ”¹è¿›äº‹ä»¶å¾ªç¯ç®¡ç†"""
        import asyncio
        import threading
        
        # è·å–æˆ–åˆ›å»ºå½“å‰çº¿ç¨‹çš„äº‹ä»¶å¾ªç¯
        try:
            loop = asyncio.get_event_loop()
            if loop.is_closed():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
        except RuntimeError:
            # å½“å‰çº¿ç¨‹æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        try:
            # åˆ›å»ºè¿›åº¦å›è°ƒ
            progress_callback = TaskProgressCallback(task_id, self)
            
            # æ‰§è¡Œå¼‚æ­¥ç¿»è¯‘
            result_files = loop.run_until_complete(
                self._do_translation(task_id, request, input_file_path, progress_callback)
            )
            
            # è®°å½•ç»“æœæ–‡ä»¶ï¼ˆç›´æ¥ä½¿ç”¨æŒä¹…åŒ–è·¯å¾„ï¼Œä¸ä¾èµ–ç¼“å­˜ï¼‰
            for result_file in result_files:
                if result_file.exists():
                    # ç›´æ¥è®°å½•æŒä¹…åŒ–æ–‡ä»¶è·¯å¾„
                    self.add_output_file(task_id, str(result_file))
                    logger.info(f"è®°å½•ç»“æœæ–‡ä»¶: {result_file}")
            
            self.update_task_status(
                task_id, 
                TaskStatus.COMPLETED, 
                f"ç¿»è¯‘å®Œæˆï¼Œç”Ÿæˆäº† {len(result_files)} ä¸ªæ–‡ä»¶"
            )
            self.update_task_progress(task_id, 100.0, "ç¿»è¯‘å®Œæˆ")
            
        except asyncio.CancelledError:
            logger.info(f"ä»»åŠ¡ {task_id} è¢«å–æ¶ˆ")
            self.update_task_status(task_id, TaskStatus.CANCELLED, "ä»»åŠ¡è¢«å–æ¶ˆ")
            
        except Exception as e:
            error_msg = f"ç¿»è¯‘ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}"
            error_traceback = traceback.format_exc()
            
            self.update_task_status(
                task_id, 
                TaskStatus.FAILED, 
                error_msg,
                error_msg,
                error_traceback
            )
            logger.error(f"ä»»åŠ¡ {task_id} æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            
        finally:
            # æ­£ç¡®æ¸…ç†äº‹ä»¶å¾ªç¯
            try:
                # å–æ¶ˆæ‰€æœ‰æœªå®Œæˆçš„ä»»åŠ¡
                pending = asyncio.all_tasks(loop)
                if pending:
                    for task in pending:
                        task.cancel()
                    
                    # ç­‰å¾…ä»»åŠ¡å–æ¶ˆå®Œæˆ
                    loop.run_until_complete(asyncio.gather(*pending, return_exceptions=True))
                
                # å®‰å…¨å…³é—­äº‹ä»¶å¾ªç¯
                loop.close()
                
            except Exception as cleanup_error:
                logger.warning(f"æ¸…ç†äº‹ä»¶å¾ªç¯æ—¶å‡ºé”™: {cleanup_error}")
                # å¼ºåˆ¶å…³é—­
                try:
                    if not loop.is_closed():
                        loop.close()
                except Exception:
                    pass

    async def _do_translation(
        self, 
        task_id: str, 
        request: TranslationRequest, 
        input_file_path: Path,
        progress_callback: TaskProgressCallback
    ) -> List[Path]:
        """æ‰§è¡Œå…·ä½“çš„ç¿»è¯‘æ“ä½œï¼Œä½¿ç”¨ CLI ç›¸åŒçš„ä¼˜åŒ–æŠ€æœ¯"""
        
        progress_callback(5.0, "åˆå§‹åŒ–ç¿»è¯‘å™¨")
        
        # åˆå§‹åŒ–ç¿»è¯‘å™¨ï¼ˆä½¿ç”¨ä¸CLIç›¸åŒçš„é…ç½®ï¼‰
        translator = OpenAITranslator(
            lang_in=request.lang_in,
            lang_out=request.lang_out,
            model=request.openai_model,
            base_url=request.openai_base_url,
            api_key=request.openai_api_key,
            ignore_cache=request.ignore_cache
        )
        
        # è®¾ç½®é€Ÿç‡é™åˆ¶ï¼ˆä¸CLIä¿æŒä¸€è‡´ï¼‰
        set_translate_rate_limiter(request.qps)
        
        progress_callback(10.0, "åŠ è½½æ–‡æ¡£å¸ƒå±€æ¨¡å‹")
        
        # åˆå§‹åŒ–æ–‡æ¡£å¸ƒå±€æ¨¡å‹
        from babeldoc.docvision.doclayout import DocLayoutModel
        doc_layout_model = DocLayoutModel.load_onnx()
        
        # è¡¨æ ¼æ¨¡å‹
        table_model = None
        if request.translate_table_text:
            from babeldoc.docvision.table_detection.rapidocr import RapidOCRModel
            table_model = RapidOCRModel()
        
        progress_callback(15.0, "åˆ›å»ºç¿»è¯‘é…ç½®")
        
        # è½¬æ¢æ°´å°æ¨¡å¼
        watermark_mode = WatermarkOutputMode.Watermarked
        if request.watermark_output_mode.value == "no_watermark":
            watermark_mode = WatermarkOutputMode.NoWatermark
        elif request.watermark_output_mode.value == "both":
            watermark_mode = WatermarkOutputMode.Both
        
        # åˆ›å»ºå•ç‹¬çš„ä¸´æ—¶å·¥ä½œç›®å½•ï¼Œé¿å…æ–‡ä»¶å†²çª
        import tempfile
        import uuid
        temp_base_dir = Path(tempfile.gettempdir()) / f"babeldoc_api_{uuid.uuid4().hex[:8]}"
        temp_base_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            # åˆ›å»ºç¿»è¯‘é…ç½®ï¼ˆä½¿ç”¨ä¸CLIå®Œå…¨ç›¸åŒçš„å‚æ•°ï¼‰
            config = TranslationConfig(
                input_file=str(input_file_path),
                translator=translator,
                doc_layout_model=doc_layout_model,
                lang_in=request.lang_in,
                lang_out=request.lang_out,
                pages=request.pages,
                output_dir=temp_base_dir / "output",
                no_dual=request.no_dual,
                no_mono=request.no_mono,
                min_text_length=request.min_text_length,
                watermark_output_mode=watermark_mode,
                qps=request.qps,
                formular_font_pattern=request.formular_font_pattern,
                formular_char_pattern=request.formular_char_pattern,
                split_short_lines=request.split_short_lines,
                short_line_split_factor=request.short_line_split_factor,
                skip_clean=request.skip_clean,
                dual_translate_first=request.dual_translate_first,
                disable_rich_text_translate=request.disable_rich_text_translate,
                enhance_compatibility=request.enhance_compatibility,
                use_alternating_pages_dual=request.use_alternating_pages_dual,
                table_model=table_model,
                show_char_box=request.show_char_box,
                skip_scanned_detection=request.skip_scanned_detection,
                ocr_workaround=request.ocr_workaround,
                custom_system_prompt=request.custom_system_prompt,
                working_dir=temp_base_dir / "work",
                skip_formula_offset_calculation=request.skip_formula_offset_calculation,
                figure_table_protection_threshold=request.figure_table_protection_threshold,
                remove_non_formula_lines=request.remove_non_formula_lines,
                enable_graphic_element_process=request.enable_graphic_element_process,
                # å…³é”®ä¼˜åŒ–ï¼šè®¾ç½®å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°
                pool_max_workers=max(request.qps, 2),  # è‡³å°‘2ä¸ªçº¿ç¨‹ï¼Œæˆ–ç­‰äºQPSå€¼
                # è¿›åº¦æŠ¥å‘Šé—´éš”
                report_interval=0.1,  # 100ms æ›´æ–°ä¸€æ¬¡è¿›åº¦
            )
            
            progress_callback(20.0, "å¼€å§‹å¼‚æ­¥PDFç¿»è¯‘")
            
            # ğŸš€ å…³é”®ä¼˜åŒ–ï¼šä½¿ç”¨CLIç›¸åŒçš„å¼‚æ­¥ç¿»è¯‘æ¥å£
            from babeldoc.format.pdf.high_level import async_translate
            
            result_files = []
            
            try:
                # å¼‚æ­¥ç¿»è¯‘ï¼Œå®æ—¶è·å–è¿›åº¦
                async for event in async_translate(config):
                    if event["type"] == "progress_update":
                        # å°†ç¿»è¯‘è¿›åº¦æ˜ å°„åˆ° 20-95% èŒƒå›´
                        mapped_progress = 20.0 + (event["overall_progress"] * 0.75)
                        # å®‰å…¨è·å–æ¶ˆæ¯ï¼Œé¿å… KeyError
                        stage = event.get('stage', 'ç¿»è¯‘ä¸­')
                        message = event.get('message', '')
                        progress_callback(
                            mapped_progress, 
                            f"{stage}: {message}" if message else stage
                        )
                    
                    elif event["type"] == "finish":
                        progress_callback(95.0, "ç¿»è¯‘å®Œæˆï¼Œæ”¶é›†ç»“æœæ–‡ä»¶")
                        
                        # è·å–ç¿»è¯‘ç»“æœ
                        translate_result = event["translate_result"]
                        logger.info(f"ç¿»è¯‘å®Œæˆï¼Œç»“æœ: {translate_result}")
                        
                        # æ”¶é›†è¾“å‡ºæ–‡ä»¶åˆ°æŒä¹…åŒ–ç›®å½•
                        for file_path in (temp_base_dir / "output").rglob("*.pdf"):
                            if file_path.is_file():
                                # åˆ›å»ºæŒä¹…åŒ–ç»“æœç›®å½•
                                result_dir = self.results_base_dir / task_id
                                result_dir.mkdir(parents=True, exist_ok=True)
                                
                                # å¤åˆ¶åˆ°æŒä¹…åŒ–ç›®å½•ï¼Œä¿æŒåŸæœ‰æ–‡ä»¶åç»“æ„
                                result_file = result_dir / file_path.name
                                import shutil
                                shutil.copy2(file_path, result_file)
                                result_files.append(result_file)
                                logger.info(f"æ”¶é›†ç»“æœæ–‡ä»¶åˆ°æŒä¹…åŒ–ç›®å½•: {result_file}")
                        
                        break
                    
                    elif event["type"] == "error":
                        error_msg = f"ç¿»è¯‘è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {event.get('error', 'æœªçŸ¥é”™è¯¯')}"
                        logger.error(error_msg)
                        raise Exception(error_msg)
                        
            except asyncio.CancelledError:
                logger.info(f"ä»»åŠ¡ {task_id} è¢«å–æ¶ˆ")
                raise
                
            except Exception as e:
                logger.error(f"å¼‚æ­¥ç¿»è¯‘å¤±è´¥: {e}", exc_info=True)
                raise
            
            progress_callback(100.0, f"ç¿»è¯‘å®Œæˆï¼Œç”Ÿæˆäº† {len(result_files)} ä¸ªæ–‡ä»¶")
            
            return result_files
            
        finally:
            # å»¶è¿Ÿæ¸…ç†ä¸´æ—¶ç›®å½•ï¼Œé¿å…æ–‡ä»¶è®¿é—®å†²çª
            try:
                import time
                time.sleep(0.5)  # ç­‰å¾…æ–‡ä»¶å¥æŸ„é‡Šæ”¾
                if temp_base_dir.exists():
                    import shutil
                    shutil.rmtree(temp_base_dir, ignore_errors=True)
            except Exception as e:
                logger.warning(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥ï¼Œå°†åœ¨åå°æ¸…ç†: {e}")
                # å¼‚æ­¥æ¸…ç†ï¼Œé¿å…é˜»å¡ä¸»æµç¨‹
                import threading
                import time
                import shutil
                def cleanup_later():
                    try:
                        time.sleep(2.0)
                        if temp_base_dir.exists():
                            shutil.rmtree(temp_base_dir, ignore_errors=True)
                    except Exception:
                        pass  # å¿½ç•¥æ¸…ç†é”™è¯¯
                threading.Thread(target=cleanup_later, daemon=True).start()

    def cancel_task(self, task_id: str) -> bool:
        """å–æ¶ˆä»»åŠ¡"""
        if task_id not in self.tasks:
            return False
        
        task = self.tasks[task_id]
        if task.status == TaskStatus.PROCESSING:
            # å®é™…çš„å–æ¶ˆé€»è¾‘éœ€è¦æ›´å¤æ‚çš„å®ç°
            # è¿™é‡Œåªæ˜¯ç®€å•æ ‡è®°ä¸ºå–æ¶ˆçŠ¶æ€
            self.update_task_status(task_id, TaskStatus.CANCELLED, "ä»»åŠ¡å·²å–æ¶ˆ")
            return True
        
        return False

    def delete_task(self, task_id: str) -> bool:
        """åˆ é™¤ä»»åŠ¡"""
        with self._lock:
            if task_id not in self.tasks:
                return False
            
            # æ¸…ç†è¾“å‡ºæ–‡ä»¶ç¼“å­˜
            task = self.tasks[task_id]
            
            # æ¸…ç†ç»“æ„åŒ–æ–‡ä»¶ä¿¡æ¯ä¸­çš„æ–‡ä»¶
            for file_info in task.output_files:
                try:
                    Path(file_info.file_path).unlink(missing_ok=True)
                except Exception as e:
                    logger.error(f"åˆ é™¤è¾“å‡ºæ–‡ä»¶å¤±è´¥: {e}")
            
            # æ¸…ç†å‘åå…¼å®¹çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            for output_file_path in task.output_file_paths:
                try:
                    Path(output_file_path).unlink(missing_ok=True)
                except Exception as e:
                    logger.error(f"åˆ é™¤è¾“å‡ºæ–‡ä»¶å¤±è´¥: {e}")
            
            # åˆ é™¤ä»»åŠ¡è®°å½•
            del self.tasks[task_id]
            if task_id in self.task_locks:
                del self.task_locks[task_id]
            if task_id in self.progress_callbacks:
                del self.progress_callbacks[task_id]
            self.processing_tasks.discard(task_id)
            
            # ä¿å­˜ä»»åŠ¡æ•°æ®
            self._save_tasks()
            
            logger.info(f"åˆ é™¤ä»»åŠ¡: {task_id}")
            return True


# å…¨å±€ä»»åŠ¡ç®¡ç†å™¨å®ä¾‹
_task_manager: Optional[TaskManager] = None
_task_manager_lock = threading.Lock()


def get_task_manager() -> TaskManager:
    """è·å–å…¨å±€ä»»åŠ¡ç®¡ç†å™¨å®ä¾‹"""
    global _task_manager
    with _task_manager_lock:
        if _task_manager is None:
            _task_manager = TaskManager()
        return _task_manager